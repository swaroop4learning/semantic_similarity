{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000be14b",
   "metadata": {},
   "source": [
    "# Siamese BiLSTM Neural Network with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b6aa5",
   "metadata": {},
   "source": [
    "<p>A Siamese BiLSTM for sentence similarity scores is a type of deep learning model that is designed to compare two input sentences and produce a score indicating how similar or dissimilar they are.</p>\n",
    "<p>The Siamese BiLSTM architecture consists of two identical sub-networks that take in the two input sentences separately and process them through a Bidirectional Long Short-Term Memory (BiLSTM) layer. The BiLSTM layer captures the contextual information of the input sentences by processing them in both forward and backward directions, and produces a sequence of hidden states for each sentence. The output of each BiLSTM layer is typically fed through a fully connected layer to produce a final similarity score. The fully connected layer is essentially a linear transformation that maps the BiLSTM output to a scalar score</p>\n",
    "<p>Various loss functions are applied:\n",
    "    <li> MSE loss - such that loss can be differentiable </li>\n",
    "    <li> Pearson Loss - assumes the linear relationship </li>\n",
    "</p>\n",
    "<p>During training, the model learns to adjust its parameters to minimize the difference between the predicted similarity scores and the true similarity scores.</p>\n",
    "\n",
    "<p>Word2vec embeddings are fed as input to the BiLSTM models</p>\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ccb9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "098317da",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = \"../data/GoogleNews-vectors-negative300.bin\"\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ffb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = word2vec.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd11e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(word2vec.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "58848d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_train_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "82ed854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('../data/cleaned_val_df1.csv')\n",
    "test_df = pd.read_csv('../data/cleaned_test_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "6f748b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['plane', 'taking']</td>\n",
       "      <td>['air', 'plane', 'taking']</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['man', 'playing', 'large', 'flute']</td>\n",
       "      <td>['man', 'playing', 'flute']</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['man', 'spreading', 'shreded', 'cheese', 'piz...</td>\n",
       "      <td>['man', 'spreading', 'shredded', 'cheese', 'un...</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['three', 'men', 'playing', 'chess']</td>\n",
       "      <td>['two', 'men', 'playing', 'chess']</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['man', 'playing', 'cello']</td>\n",
       "      <td>['man', 'seated', 'playing', 'cello']</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent1  \\\n",
       "0                                ['plane', 'taking']   \n",
       "1               ['man', 'playing', 'large', 'flute']   \n",
       "2  ['man', 'spreading', 'shreded', 'cheese', 'piz...   \n",
       "3               ['three', 'men', 'playing', 'chess']   \n",
       "4                        ['man', 'playing', 'cello']   \n",
       "\n",
       "                                               sent2  score  \n",
       "0                         ['air', 'plane', 'taking']   5.00  \n",
       "1                        ['man', 'playing', 'flute']   3.80  \n",
       "2  ['man', 'spreading', 'shredded', 'cheese', 'un...   3.80  \n",
       "3                 ['two', 'men', 'playing', 'chess']   2.60  \n",
       "4              ['man', 'seated', 'playing', 'cello']   4.25  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "1401ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sent1'] = df['sent1'].apply(eval)\n",
    "df['sent2'] = df['sent2'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "53a088da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = list(df['sent1'])\n",
    "sent2 = list(df['sent2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "3326ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/word_dict_v1.pickle', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0afdcbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ae3d782d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10072"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "2099b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list.append(\"unk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "16391247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10073"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "daff3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = [i for i in vocab_list if i in word2idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "04a0de0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "562a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {k:i for i,k in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "ab01f627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "77191e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8499"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f0c0777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_trunc = {}\n",
    "for i in list(vocab_dict.keys()):\n",
    "  word2idx_trunc[vocab_dict[i]] = word2idx[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "46e2230d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459665"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b1cbba1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459665"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_trunc[8499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "46e1edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes = list(word2idx_trunc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1f8ec35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_embedding_matrix = word2vec.vectors[word_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "4fbd115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "1593a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(subset_embedding_matrix[8499], embedding_matrix[1459665])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "02831aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, sentences1, sentences2, scores, word_to_ix):\n",
    "        self.sentences1 = sentences1\n",
    "        self.sentences2 = sentences2\n",
    "        self.scores = scores\n",
    "        self.word_to_ix = word_to_ix\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.sentences1),len(self.sentences2))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        unk_token = self.word_to_ix['unk']\n",
    "        sentence1 = self.sentences1[idx]\n",
    "        sentence2 = self.sentences2[idx]\n",
    "        score = self.scores[idx]\n",
    "        seq1 = [self.word_to_ix[word] if word in self.word_to_ix else unk_token for word in sentence1]\n",
    "        seq2 = [self.word_to_ix[word] if word in self.word_to_ix else unk_token for word in sentence2]\n",
    "        #seq1 = [self.word_to_ix[word] for word in sentence1 if word in self.word_to_ix]\n",
    "        #seq2 = [self.word_to_ix[word] for word in sentence2 if word in self.word_to_ix]\n",
    "        return seq1, seq2, score\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        sequences1, sequences2, scores = zip(*batch)\n",
    "        padded_seqs1 = pad_sequence([torch.LongTensor(seq) for seq in sequences1], batch_first=True, padding_value=0)\n",
    "        padded_seqs2 = pad_sequence([torch.LongTensor(seq) for seq in sequences2], batch_first=True, padding_value=0)\n",
    "        #return padded_seqs1, padded_seqs2, torch.tensor(scores, dtype=torch.float)\n",
    "        return padded_seqs1, padded_seqs2, torch.LongTensor(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "5edcfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1_tokens = list(df['sent1'])\n",
    "sent2_tokens = list(df['sent2'])\n",
    "scores = list(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "5aaf3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = vocab_dict\n",
    "train_dataset = MyDataset(sent1_tokens, sent2_tokens, scores, word_to_ix)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "814cd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sent1_tokens = list(val_df['sent1'])\n",
    "val_sent2_tokens = list(val_df['sent2'])\n",
    "val_scores = list(val_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "676185e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MyDataset(val_sent1_tokens, val_sent2_tokens, val_scores, word_to_ix)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, collate_fn=val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "65eea0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent1_tokens = list(test_df['sent1'])\n",
    "test_sent2_tokens = list(test_df['sent2'])\n",
    "test_scores = list(test_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "1149c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_sent1_tokens, test_sent2_tokens, test_scores, word_to_ix)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fa53a47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "683c222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, 300)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "97781f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SiameseBiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, embedding_dim, embd_matrix, dropout=0.2):\n",
    "        super(SiameseBiLSTM, self).__init__()\n",
    "\n",
    "        # LSTM parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embd_matrix = embd_matrix\n",
    "\n",
    "        # Word embeddings\n",
    "        self.word_embeddings = nn.Embedding(len(embd_matrix), embedding_dim)\n",
    "        self.word_embeddings.weight = nn.Parameter(torch.from_numpy(self.embd_matrix))\n",
    "        self.word_embeddings.weight.requires_grad = False\n",
    "\n",
    "        # BiLSTM layers\n",
    "        self.bilstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                              batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Attention layers\n",
    "        self.attention_fc = nn.Linear(hidden_size * 2, 1)\n",
    "        self.attention_softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Similarity scoring layer\n",
    "        self.fc = nn.Linear(hidden_size * 4, 1)  # 4 because we concatenate forward and backward hidden states of both LSTMs\n",
    "\n",
    "    def forward_once(self, sentence):\n",
    "        # Word embeddings\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        # BiLSTM\n",
    "        lstm_out, _ = self.bilstm(embeds)\n",
    "\n",
    "        # Apply dropout to hidden layers\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention_softmax(self.attention_fc(lstm_out))\n",
    "        lstm_out = lstm_out * attention_weights\n",
    "        lstm_out = lstm_out.sum(dim=1)\n",
    "\n",
    "        return lstm_out\n",
    "\n",
    "    def forward(self, sentence1, sentence2):\n",
    "        # Process sentence 1\n",
    "        output1 = self.forward_once(sentence1)\n",
    "\n",
    "        # Process sentence 2\n",
    "        output2 = self.forward_once(sentence2)\n",
    "\n",
    "        # Concatenate outputs of both LSTMs\n",
    "        concatenated = torch.cat((output1, output2), dim=1)\n",
    "\n",
    "        # Pass through similarity scoring layer\n",
    "        similarity_score = torch.sigmoid(self.fc(concatenated))\n",
    "\n",
    "        return similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "e802c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "class PearsonLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PearsonLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        pearson_r, _ = pearsonr(pred.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "        loss = 1 - pearson_r\n",
    "        return torch.tensor(loss, requires_grad=True, device=pred.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "b7032e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/8lc9v2sx5mq19kgysgv67bzw0000gn/T/ipykernel_3432/2094664751.py:31: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return padded_seqs1, padded_seqs2, torch.LongTensor(scores)\n",
      "/var/folders/gb/8lc9v2sx5mq19kgysgv67bzw0000gn/T/ipykernel_3432/992830487.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score_tensor = torch.tensor(score, dtype=torch.float)/5.0\n",
      "/var/folders/gb/8lc9v2sx5mq19kgysgv67bzw0000gn/T/ipykernel_3432/992830487.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_score_tensor = torch.tensor(val_score, dtype=torch.float)/5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.7830, Val Loss: 0.8916\n",
      "Epoch [2/10], Train Loss: 0.7847, Val Loss: 0.8830\n",
      "Epoch [3/10], Train Loss: 0.7799, Val Loss: 0.8753\n",
      "Epoch [4/10], Train Loss: 0.7798, Val Loss: 0.8873\n",
      "Epoch [5/10], Train Loss: 0.7750, Val Loss: 0.8754\n",
      "Epoch [6/10], Train Loss: 0.7777, Val Loss: 0.8769\n",
      "Epoch [7/10], Train Loss: 0.7726, Val Loss: 0.8778\n",
      "Epoch [8/10], Train Loss: 0.7726, Val Loss: 0.8916\n",
      "Epoch [9/10], Train Loss: 0.7816, Val Loss: 0.8686\n",
      "Epoch [10/10], Train Loss: 0.7775, Val Loss: 0.8709\n"
     ]
    }
   ],
   "source": [
    "# Define model and optimizer\n",
    "model = SiameseBiLSTM(hidden_size=50, num_layers=2, embedding_dim=300, embd_matrix = subset_embedding_matrix)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define loss function\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = PearsonLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for i, (sentence1, sentence2, score) in enumerate(train_dataloader):\n",
    "        # Convert inputs and output to PyTorch tensors\n",
    "        sentence1_tensor = sentence1\n",
    "        sentence2_tensor = sentence2\n",
    "        score_tensor = torch.tensor(score, dtype=torch.float)/5.0\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(sentence1_tensor, sentence2_tensor)\n",
    "        \n",
    "        #print(score_tensor.squeeze().shape)\n",
    "        # Compute loss\n",
    "        #loss = criterion(outputs, score_tensor.unsqueeze(-1))\n",
    "        loss = criterion(output.squeeze(), score_tensor.squeeze())\n",
    "        #loss = model.loss(output, score_tensor.unsqueeze(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()  # add batch loss to total epoch loss\n",
    "        \n",
    "     # Validation loop\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for j, (val_sentence1, val_sentence2, val_score) in enumerate(val_dataloader):\n",
    "            val_sentence1_tensor = val_sentence1\n",
    "            val_sentence2_tensor = val_sentence2\n",
    "            val_score_tensor = torch.tensor(val_score, dtype=torch.float)/5.0\n",
    "            outputs = model(val_sentence1_tensor, val_sentence2_tensor)\n",
    "            #val_loss = criterion(outputs, val_score_tensor.unsqueeze(-1))\n",
    "            val_loss = criterion(outputs.squeeze(), val_score_tensor.squeeze())\n",
    "            #val_loss = model.loss(outputs, val_score_tensor.unsqueeze(-1))\n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "    avg_train_loss = epoch_loss / len(train_dataloader) \n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "52411642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/8lc9v2sx5mq19kgysgv67bzw0000gn/T/ipykernel_3432/2094664751.py:31: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return padded_seqs1, padded_seqs2, torch.LongTensor(scores)\n",
      "/var/folders/gb/8lc9v2sx5mq19kgysgv67bzw0000gn/T/ipykernel_3432/2390986877.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_score_tensor = torch.tensor(test_score, dtype=torch.float)/5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 5.6369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "model.eval()  # set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for k, (test_sentence1, test_sentence2, test_score) in enumerate(test_dataloader):\n",
    "        test_sentence1_tensor = test_sentence1\n",
    "        test_sentence2_tensor = test_sentence2\n",
    "        test_score_tensor = torch.tensor(test_score, dtype=torch.float)/5.0\n",
    "        test_output = model(test_sentence1_tensor, test_sentence2_tensor)\n",
    "        test_predictions.extend(test_output.tolist())\n",
    "        test_labels.extend(test_score)\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_labels = np.array(test_labels)\n",
    "test_mse = mean_squared_error(test_labels, test_predictions)\n",
    "print('Test MSE: {:.4f}'.format(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "34ba8df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68017125],\n",
       "       [0.61859626],\n",
       "       [0.62256104],\n",
       "       ...,\n",
       "       [0.59949923],\n",
       "       [0.68392903],\n",
       "       [0.64198142]])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "df4a7631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "cae60193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1379, 1), (1379,))"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "0eec70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def pearson_corr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Pearson correlation coefficient between two arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "890b925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pearson_corr(test_labels, test_predictions.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "c5b4d168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1299918837761417"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7a832f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "22de0953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8499"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "b4a10d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../data/siamese_model_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be667ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
