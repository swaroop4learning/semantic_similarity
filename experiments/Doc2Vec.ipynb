{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba7fd8d",
   "metadata": {},
   "source": [
    "<h1> Doc2Vec embeddings </h1>\n",
    "<p>Doc2Vec model is trained to generate representative embeddings of sentences and with these embeddings following approaches are applied to generate STS scores:</p>\n",
    "<li>Normalized cosine similarity score </li>\n",
    "<li>BiLSTM Regression neural network model</li>\n",
    "<li>BiGRU Regression neural network model</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8cca6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "272ca941",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/cleaned_train_df.csv')\n",
    "val_df = pd.read_csv('../data/cleaned_val_df.csv')\n",
    "test_df = pd.read_csv('../data/cleaned_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f07472d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sent1'] = train_df['sent1'].apply(eval)\n",
    "train_df['sent2'] = train_df['sent2'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abb9ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['sent1'] = val_df['sent1'].apply(eval)\n",
    "val_df['sent2'] = val_df['sent2'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "367cdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['sent1'] = test_df['sent1'].apply(eval)\n",
    "test_df['sent2'] = test_df['sent2'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c70ae2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sents_unk = list(train_df['sent1'])\n",
    "total_sents_unk.extend(list(train_df['sent2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ec8dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for idx, sent in enumerate(total_sents_unk):\n",
    "    documents.append(TaggedDocument(sent, [idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b04b96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['a', 'plane', 'is', 'take', 'off'], tags=[0]),\n",
       " TaggedDocument(words=['a', 'man', 'is', 'play', 'a', 'larg', 'flute'], tags=[1]),\n",
       " TaggedDocument(words=['a', 'man', 'is', 'spread', 'unk', 'chees', 'on', 'a', 'pizza'], tags=[2]),\n",
       " TaggedDocument(words=['three', 'men', 'are', 'play', 'chess'], tags=[3]),\n",
       " TaggedDocument(words=['a', 'man', 'is', 'play', 'the', 'cello'], tags=[4])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "400d8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=25, window=6, min_count=1, workers=1, epochs=30, alpha=0.1, min_alpha=0.001, hs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28a53fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sentence embeddings\n",
    "embedding1 = model.infer_vector(train_df['sent1'][0])\n",
    "embedding2 = model.infer_vector(train_df['sent2'][0])\n",
    "\n",
    "# Compare the sentence embeddings using cosine similarity\n",
    "similarity = 1 - spatial.distance.cosine(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bca5e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sts_score(sim_score):\n",
    "    sts_score = (sim_score+1) * 2.5\n",
    "    return sts_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cd831e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.random.seed(42)\n",
    "train_df['sent1_embedding'] = train_df['sent1'].apply(lambda x: model.infer_vector(x))\n",
    "train_df['sent2_embedding'] = train_df['sent2'].apply(lambda x: model.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c53c98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['y_pred'] = train_df.apply(lambda x: sts_score(1 - spatial.distance.cosine(x['sent1_embedding'], x['sent2_embedding'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98d3a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = train_df['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e644b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f00724b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "def pearson_corr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Pearson correlation coefficient between two arrays.\n",
    "    \"\"\"\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c0f0cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient between predicted values and target values\n",
    "corr = pearson_corr(y_train, y_pred)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Pearson correlation coefficient: {:.2f}\".format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3e498b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.random.seed(42)\n",
    "val_df['sent1_embedding'] = val_df['sent1'].apply(lambda x: model.infer_vector(x))\n",
    "val_df['sent2_embedding'] = val_df['sent2'].apply(lambda x: model.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd9ae68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['y_pred'] = val_df.apply(lambda x: sts_score(1 - spatial.distance.cosine(x['sent1_embedding'], x['sent2_embedding'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "091edb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = val_df['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89edbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c73db559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient between predicted values and target values\n",
    "corr = pearson_corr(y_val, y_val_pred)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Pearson correlation coefficient: {:.2f}\".format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e404107",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.random.seed(42)\n",
    "test_df['sent1_embedding'] = test_df['sent1'].apply(lambda x: model.infer_vector(x))\n",
    "test_df['sent2_embedding'] = test_df['sent2'].apply(lambda x: model.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94a2119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['y_pred'] = test_df.apply(lambda x: sts_score(1 - spatial.distance.cosine(x['sent1_embedding'], x['sent2_embedding'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92bc283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = test_df['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4059fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64a74d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient between predicted values and target values\n",
    "corr = pearson_corr(y_test, y_test_pred)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Pearson correlation coefficient: {:.2f}\".format(corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67856c",
   "metadata": {},
   "source": [
    "# BILstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5e81a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1 = list(train_df['sent1_embedding'])\n",
    "embeddings2 = list(train_df['sent2_embedding'])\n",
    "scores = list(train_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e2ca6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings1 = list(val_df['sent1_embedding'])\n",
    "val_embeddings2 = list(val_df['sent2_embedding'])\n",
    "val_scores = list(val_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dacafd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AH00434/opt/anaconda3/envs/nlp_venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Convert the data into PyTorch tensors\n",
    "embeddings1 = torch.tensor(embeddings1, dtype=torch.float)\n",
    "embeddings2 = torch.tensor(embeddings2, dtype=torch.float)\n",
    "scores = torch.tensor(scores, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e41b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings1 = torch.tensor(val_embeddings1, dtype=torch.float)\n",
    "val_embeddings2 = torch.tensor(val_embeddings2, dtype=torch.float)\n",
    "val_scores = torch.tensor(val_scores, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "485d300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings1 = embeddings1\n",
    "train_embeddings2 = embeddings2\n",
    "train_scores = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "add82296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "input_dim = 25 # The dimension of the sentence embeddings\n",
    "hidden_dim = 25\n",
    "lr = 0.001\n",
    "num_epochs = 5\n",
    "#batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b6d6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMRegression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bilstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = x.view(len(x), 1, -1)\n",
    "        h0 = torch.zeros(self.num_layers*2, len(x), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers*2, len(x), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.bilstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "96f51481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and optimizer\n",
    "#model = SentenceSimilarityModel(input_dim*2, hidden_dim)\n",
    "model = BiLSTMRegression(input_dim*2, hidden_dim, num_layers=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21f2e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "# Define a custom dataset class\n",
    "class SentenceSimilarityDataset(data.Dataset):\n",
    "    def __init__(self, embeddings1, embeddings2, scores):\n",
    "        self.embeddings1 = embeddings1\n",
    "        self.embeddings2 = embeddings2\n",
    "        self.scores = scores\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.embeddings1[index], self.embeddings2[index], self.scores[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e942662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_dataset = SentenceSimilarityDataset(train_embeddings1, train_embeddings2, train_scores)\n",
    "val_dataset = SentenceSimilarityDataset(val_embeddings1, val_embeddings2, val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1ef58be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ceb8bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 2.8065, Validation Loss: 2.0717\n",
      "Epoch 2 - Training Loss: 1.6861, Validation Loss: 1.9265\n",
      "Epoch 3 - Training Loss: 1.4261, Validation Loss: 1.9203\n",
      "Epoch 4 - Training Loss: 1.2171, Validation Loss: 1.9439\n",
      "Epoch 5 - Training Loss: 1.0567, Validation Loss: 2.0148\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        embeddings1_batch, embeddings2_batch, scores_batch = batch\n",
    "        output = model(embeddings1_batch, embeddings2_batch)\n",
    "        loss = loss_fn(output.squeeze(), scores_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * len(embeddings1_batch)\n",
    "    train_loss /= len(train_embeddings1)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            embeddings1_batch, embeddings2_batch, scores_batch = batch\n",
    "            val_output = model(embeddings1_batch, embeddings2_batch)\n",
    "            val_loss += loss_fn(val_output.squeeze(), scores_batch).item() * len(embeddings1_batch)\n",
    "        val_loss /= len(val_embeddings1)\n",
    "\n",
    "    print('Epoch {} - Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch+1, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7eea6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings1 = list(test_df['sent1_embedding'])\n",
    "test_embeddings2 = list(test_df['sent2_embedding'])\n",
    "test_scores = list(test_df['score'])\n",
    "test_embeddings1 = torch.tensor(test_embeddings1, dtype=torch.float)\n",
    "test_embeddings2 = torch.tensor(test_embeddings2, dtype=torch.float)\n",
    "test_scores = torch.tensor(test_scores, dtype=torch.float)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = model(test_embeddings1, test_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3b6dad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = test_output.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "01eb1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f7a76283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient between predicted values and target values\n",
    "corr = pearson_corr(y_test, y_pred_test)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Pearson correlation coefficient: {:.2f}\".format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b41fb20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRURegression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = x.view(len(x), 1, -1)\n",
    "        h0 = torch.zeros(self.num_layers*2, len(x), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bdca2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRURegression(input_dim*2, hidden_dim, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eb8f98ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 9.2868, Validation Loss: 7.6936\n",
      "Epoch 2 - Training Loss: 9.2868, Validation Loss: 7.6936\n",
      "Epoch 3 - Training Loss: 9.2868, Validation Loss: 7.6936\n",
      "Epoch 4 - Training Loss: 9.2868, Validation Loss: 7.6936\n",
      "Epoch 5 - Training Loss: 9.2868, Validation Loss: 7.6936\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        embeddings1_batch, embeddings2_batch, scores_batch = batch\n",
    "        output = model(embeddings1_batch, embeddings2_batch)\n",
    "        loss = loss_fn(output.squeeze(), scores_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * len(embeddings1_batch)\n",
    "    train_loss /= len(train_embeddings1)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            embeddings1_batch, embeddings2_batch, scores_batch = batch\n",
    "            val_output = model(embeddings1_batch, embeddings2_batch)\n",
    "            val_loss += loss_fn(val_output.squeeze(), scores_batch).item() * len(embeddings1_batch)\n",
    "        val_loss /= len(val_embeddings1)\n",
    "\n",
    "    print('Epoch {} - Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch+1, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ace04631",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings1 = list(test_df['sent1_embedding'])\n",
    "test_embeddings2 = list(test_df['sent2_embedding'])\n",
    "test_scores = list(test_df['score'])\n",
    "test_embeddings1 = torch.tensor(test_embeddings1, dtype=torch.float)\n",
    "test_embeddings2 = torch.tensor(test_embeddings2, dtype=torch.float)\n",
    "test_scores = torch.tensor(test_scores, dtype=torch.float)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = model(test_embeddings1, test_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eabff3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = test_output.squeeze().tolist()\n",
    "y_test = test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "643f6544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: -0.02\n"
     ]
    }
   ],
   "source": [
    "corr = pearson_corr(y_test, y_pred_test)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Pearson correlation coefficient: {:.2f}\".format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "02d86845",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1 = list(train_df['sent1_embedding'])\n",
    "embeddings2 = list(train_df['sent2_embedding'])\n",
    "scores = list(train_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b4cd4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings1 = list(val_df['sent1_embedding'])\n",
    "val_embeddings2 = list(val_df['sent2_embedding'])\n",
    "val_scores = list(val_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "211bf014",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings1 = list(test_df['sent1_embedding'])\n",
    "test_embeddings2 = list(test_df['sent2_embedding'])\n",
    "test_scores = list(test_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d99c4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sentence embeddings\n",
    "X1 = np.array(embeddings1)\n",
    "X2 = np.array(embeddings2)\n",
    "# generate sentence embeddings\n",
    "val_X1 = np.array(val_embeddings1)\n",
    "val_X2 = np.array(val_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bb5d30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X1 = np.array(test_embeddings1)\n",
    "test_X2 = np.array(test_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fdacffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#concatenate sentence embeddings to create feature matrix\n",
    "X = np.concatenate([X1, X2], axis=1)\n",
    "\n",
    "# train a linear regression model\n",
    "reg = LinearRegression().fit(X, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8e136226",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = np.concatenate([val_X1, val_X2], axis=1)\n",
    "val_y_pred = reg.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e858be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.07\n"
     ]
    }
   ],
   "source": [
    "corr = pearson_corr(val_scores, val_y_pred)\n",
    "print(\"Pearson correlation coefficient: {:.2f}\".format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "852a85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate sentence embeddings to create feature matrix\n",
    "test_X = np.concatenate([test_X1, test_X2], axis=1)\n",
    "test_y_pred = reg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0c087b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.11\n"
     ]
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient between predicted values and target values\n",
    "corr = pearson_corr(test_scores, test_y_pred)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Pearson correlation coefficient: {:.2f}\".format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "efefe462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>score</th>\n",
       "      <th>sent1_embedding</th>\n",
       "      <th>sent2_embedding</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, plane, is, take, off]</td>\n",
       "      <td>[an, air, plane, is, take, off]</td>\n",
       "      <td>5.00</td>\n",
       "      <td>[-0.4224272, -2.6225648, 1.2613771, -1.0724506...</td>\n",
       "      <td>[-1.5233037, -1.2017787, 1.3848532, -1.6483687...</td>\n",
       "      <td>4.266091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a, man, is, play, a, larg, flute]</td>\n",
       "      <td>[a, man, is, play, a, flute]</td>\n",
       "      <td>3.80</td>\n",
       "      <td>[-0.5728938, 1.937188, -0.59581786, 2.0941627,...</td>\n",
       "      <td>[0.30465078, 0.5849875, -0.21188323, 0.2666212...</td>\n",
       "      <td>4.220219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, man, is, spread, unk, chees, on, a, pizza]</td>\n",
       "      <td>[a, man, is, spread, shred, chees, on, an, unk...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>[-0.34313184, -0.74568987, 0.19610271, -0.7560...</td>\n",
       "      <td>[0.6708356, 0.45349512, 1.2122866, 9.2444825e-...</td>\n",
       "      <td>3.646576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[three, men, are, play, chess]</td>\n",
       "      <td>[two, men, are, play, chess]</td>\n",
       "      <td>2.60</td>\n",
       "      <td>[1.751888, -0.30320084, 0.28331283, 0.30995673...</td>\n",
       "      <td>[1.272545, -0.33465645, -0.6245619, 0.8188742,...</td>\n",
       "      <td>4.547019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[a, man, is, play, the, cello]</td>\n",
       "      <td>[a, man, seat, is, play, the, cello]</td>\n",
       "      <td>4.25</td>\n",
       "      <td>[-0.06809825, -0.06937426, -2.022168, -0.36487...</td>\n",
       "      <td>[-1.2138389, -2.2551486, -2.0910704, 1.0399933...</td>\n",
       "      <td>4.203823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sent1  \\\n",
       "0                       [a, plane, is, take, off]   \n",
       "1              [a, man, is, play, a, larg, flute]   \n",
       "2  [a, man, is, spread, unk, chees, on, a, pizza]   \n",
       "3                  [three, men, are, play, chess]   \n",
       "4                  [a, man, is, play, the, cello]   \n",
       "\n",
       "                                               sent2  score  \\\n",
       "0                    [an, air, plane, is, take, off]   5.00   \n",
       "1                       [a, man, is, play, a, flute]   3.80   \n",
       "2  [a, man, is, spread, shred, chees, on, an, unk...   3.80   \n",
       "3                       [two, men, are, play, chess]   2.60   \n",
       "4               [a, man, seat, is, play, the, cello]   4.25   \n",
       "\n",
       "                                     sent1_embedding  \\\n",
       "0  [-0.4224272, -2.6225648, 1.2613771, -1.0724506...   \n",
       "1  [-0.5728938, 1.937188, -0.59581786, 2.0941627,...   \n",
       "2  [-0.34313184, -0.74568987, 0.19610271, -0.7560...   \n",
       "3  [1.751888, -0.30320084, 0.28331283, 0.30995673...   \n",
       "4  [-0.06809825, -0.06937426, -2.022168, -0.36487...   \n",
       "\n",
       "                                     sent2_embedding    y_pred  \n",
       "0  [-1.5233037, -1.2017787, 1.3848532, -1.6483687...  4.266091  \n",
       "1  [0.30465078, 0.5849875, -0.21188323, 0.2666212...  4.220219  \n",
       "2  [0.6708356, 0.45349512, 1.2122866, 9.2444825e-...  3.646576  \n",
       "3  [1.272545, -0.33465645, -0.6245619, 0.8188742,...  4.547019  \n",
       "4  [-1.2138389, -2.2551486, -2.0910704, 1.0399933...  4.203823  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da6cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
